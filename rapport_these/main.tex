\documentclass[a4paper]{book}

\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{etoolbox}
\usepackage{url}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{fancyref}
\usepackage{amsmath}
\usepackage{listings}
\usepackage{url}
\usepackage{float}
\usepackage{amssymb}
\usepackage{rotating}
\usepackage{multirow}
\usepackage[toc,page]{appendix}
\usepackage{mdframed}
\usepackage[usenames,dvipsnames]{xcolor}
\usepackage{indentfirst}

\usepackage{tikz}
\usepackage{pgfplots}
\usetikzlibrary{shapes}
\usepackage[ruled,linesnumbered,vlined]{algorithm2e}

\usepackage{verbatim}

\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\argmin}{\arg\!\min}


\usepackage{tikz}
\usetikzlibrary{decorations.pathreplacing}

\title{audio-visual perception for recognition of human activities and object affordances for assistant robots.}


\begin{document}
	\maketitle
	\tableofcontents

	% \include{introduction}
	% \include{neural_networks}
	\include{ccn}
	% \include{deep_learning_techniques}
	% \include{saliency}	


	

	\bibliographystyle{plain}
	\bibliography{papers}


\end{document}



